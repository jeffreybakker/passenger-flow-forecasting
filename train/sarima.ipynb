{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "SEED = 3\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOADING DATA: 100%|██████████| 6/6 [00:19<00:00,  3.22s/it]\n",
      "LOADING DATA: 100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n",
      "LOADING DATA: 100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                        passengers     noise\ndatetime            origin destination                      \n2022-01-01 00:00:00 12     19                159.0  1.788628\n                           LM                  6.0  0.436510\n                           OW                 25.0  0.096497\n                    16     24                 78.0 -1.863493\n                           CC                 82.0 -0.277388\n...                                            ...       ...\n2022-12-31 23:00:00 WD     ED                 17.0 -1.369044\n                    WP     NC                 14.0 -1.853796\n                           PC                 35.0 -1.561378\n                    WS     FM                121.0 -0.871452\n                           ML                 16.0  1.432205\n\n[893520 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>passengers</th>\n      <th>noise</th>\n    </tr>\n    <tr>\n      <th>datetime</th>\n      <th>origin</th>\n      <th>destination</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2022-01-01 00:00:00</th>\n      <th rowspan=\"3\" valign=\"top\">12</th>\n      <th>19</th>\n      <td>159.0</td>\n      <td>1.788628</td>\n    </tr>\n    <tr>\n      <th>LM</th>\n      <td>6.0</td>\n      <td>0.436510</td>\n    </tr>\n    <tr>\n      <th>OW</th>\n      <td>25.0</td>\n      <td>0.096497</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">16</th>\n      <th>24</th>\n      <td>78.0</td>\n      <td>-1.863493</td>\n    </tr>\n    <tr>\n      <th>CC</th>\n      <td>82.0</td>\n      <td>-0.277388</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2022-12-31 23:00:00</th>\n      <th>WD</th>\n      <th>ED</th>\n      <td>17.0</td>\n      <td>-1.369044</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WP</th>\n      <th>NC</th>\n      <td>14.0</td>\n      <td>-1.853796</td>\n    </tr>\n    <tr>\n      <th>PC</th>\n      <td>35.0</td>\n      <td>-1.561378</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WS</th>\n      <th>FM</th>\n      <td>121.0</td>\n      <td>-0.871452</td>\n    </tr>\n    <tr>\n      <th>ML</th>\n      <td>16.0</td>\n      <td>1.432205</td>\n    </tr>\n  </tbody>\n</table>\n<p>893520 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from util.dataset import PassengerFlowDataset\n",
    "from util.transform import PandasToTensor, RollExogenousFeatures\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    PandasToTensor(),\n",
    "    RollExogenousFeatures()\n",
    "])\n",
    "\n",
    "train_data = PassengerFlowDataset(\n",
    "    min_date=date(2022, 1, 1),\n",
    "    max_date=date(2023, 1, 1),\n",
    "    transform=transform)\n",
    "validation_data = PassengerFlowDataset(\n",
    "    min_date=date(2023, 1, 1),\n",
    "    max_date=date(2023, 4, 1),\n",
    "    transform=transform)\n",
    "test_data = PassengerFlowDataset(\n",
    "    min_date=date(2023, 4, 1),\n",
    "    max_date=date(2023, 7, 1),\n",
    "    transform=transform)\n",
    "\n",
    "train_data._data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "validation_loader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from models.sarima import SARIMA\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = SARIMA(order=(23, 1, 0),\n",
    "               seasonal_lag=24,\n",
    "               seasonal_order=(7, 0, 0)\n",
    "               ).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1.0e-3, eps=1.0e-4)\n",
    "scheduler = ExponentialLR(optimizer, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Log run to Weights and Biases\n",
    "run = wandb.init(\n",
    "    project='passenger-flow-forecasting',\n",
    "    config={\n",
    "        'model': 'SARIMA',\n",
    "        'p': model._order[0],\n",
    "        'd': model._order[1],\n",
    "        'q': model._order[2],\n",
    "        'P': model._seasonal_order[0],\n",
    "        'D': model._seasonal_order[1],\n",
    "        'Q': model._seasonal_order[2]\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "EPOCH:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae5a09c9416146ad8528a35f03e5e168"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TRAIN: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d0be9826a9d47658d1e11be6c3bb726"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0    RMSE: 139.97    MAE: 73.45\n",
      "# 1    RMSE: 128.53    MAE: 59.83\n",
      "# 2    RMSE: 127.28    MAE: 57.77\n",
      "# 3    RMSE: 128.66    MAE: 58.52\n",
      "# 4    RMSE: 128.44    MAE: 59.29\n",
      "# 5    RMSE: 128.58    MAE: 58.48\n",
      "# 6    RMSE: 129.14    MAE: 58.47\n",
      "# 7    RMSE: 128.41    MAE: 58.50\n",
      "# 8    RMSE: 129.28    MAE: 58.21\n",
      "# 9    RMSE: 128.68    MAE: 58.45\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "last_state = (-1, None)\n",
    "\n",
    "# Create weights directories\n",
    "os.makedirs('weights/sarima/checkpoints', exist_ok=True)\n",
    "\n",
    "tqdm_epoch = tqdm(desc='EPOCH', total=EPOCHS)\n",
    "tqdm_batch = tqdm(desc='TRAIN', total=0)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Keep track of the training loss\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Loop over training data in batches\n",
    "    tqdm_batch.reset(len(train_loader))\n",
    "    tqdm_batch.desc = 'TRAIN'\n",
    "    for batch in train_loader:\n",
    "        # Move the data to the same device as the model\n",
    "        history, horizon = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Select views of data\n",
    "        y = horizon[:, 0, 0].squeeze()\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute outputs using a forward pass\n",
    "        outputs = model(history, horizon).squeeze()\n",
    "\n",
    "        # Compute the training loss of this batch\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Perform a backward pass to update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Keep track of training loss\n",
    "        y_true += y.cpu().numpy().tolist()\n",
    "        y_pred += outputs.cpu().detach().numpy().tolist()\n",
    "\n",
    "        tqdm_batch.update()\n",
    "\n",
    "    train_mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    train_mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # We don't need to keep track of gradients while testing on the validation set\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # Loop over data in batches\n",
    "        tqdm_batch.reset(len(validation_loader))\n",
    "        tqdm_batch.desc = 'VALIDATE'\n",
    "        for batch in validation_loader:\n",
    "            # Move the data to the same device as the model\n",
    "            history, horizon = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Select views of data\n",
    "            y = horizon[:, 0, 0].squeeze()\n",
    "\n",
    "            # Compute outputs using a forward pass\n",
    "            outputs = model(history, horizon).squeeze()\n",
    "\n",
    "            # Keep track of validation loss\n",
    "            y_true += y.cpu().numpy().tolist()\n",
    "            y_pred += outputs.cpu().detach().numpy().tolist()\n",
    "\n",
    "            tqdm_batch.update()\n",
    "\n",
    "    validation_mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    validation_mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    print(f'#{epoch:2d}    RMSE: {math.sqrt(validation_mse):.2f}    MAE: {validation_mae:.2f}')\n",
    "\n",
    "    # Log metrics to Weights and Biases\n",
    "    wandb.log({\n",
    "        'train_mse': train_mse,\n",
    "        'train_mae': train_mae,\n",
    "        'validation_mse': validation_mse,\n",
    "        'validation_mae': validation_mae\n",
    "    }, commit=epoch < EPOCHS - 1)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    last_state = epoch, model.state_dict()\n",
    "\n",
    "    if epoch < 5 or epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'weights/sarima/checkpoints/{epoch:2d}.pt')\n",
    "\n",
    "    tqdm_epoch.update()\n",
    "\n",
    "tqdm_batch.close()\n",
    "tqdm_epoch.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "now = datetime.now()\n",
    "datestring = f'{now.year}{str(now.month).zfill(2)}{str(now.day).zfill(2)}-{str(now.hour).zfill(2)}{str(now.minute).zfill(2)}'\n",
    "torch.save(last_state[1], f'weights/sarima/{datestring}--{last_state[0]}.pt')\n",
    "torch.save(last_state[1], f'weights/sarima/seed-{SEED}.pt')\n",
    "torch.save(last_state[1], f'weights/sarima/latest.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "if exists(f'weights/sarima/latest.pt'):\n",
    "    model.load_state_dict(torch.load(f'weights/sarima/latest.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "TEST:   0%|          | 0/775 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "771a371c1cc443328bcc4168d38efbe3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18154.36\n",
      "RMSE: 134.74\n",
      "MAE: 60.77\n",
      "MAPE: 2.79\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Keep track of the loss\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# We don't need to keep track of gradients while testing\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    # Loop over data in batches\n",
    "    for batch in tqdm(test_loader, desc='TEST'):\n",
    "        # Move the data to the same device as the model\n",
    "        history, horizon = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Select views of data\n",
    "        y = horizon[:, 0, 0].squeeze()\n",
    "\n",
    "        # Compute outputs using a forward pass\n",
    "        outputs = model(history, horizon).squeeze()\n",
    "\n",
    "        # Keep track of loss\n",
    "        y_true += y.cpu().numpy().tolist()\n",
    "        y_pred += outputs.cpu().detach().numpy().tolist()\n",
    "\n",
    "        tqdm_batch.update()\n",
    "\n",
    "test_mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "test_rmse = metrics.mean_squared_error(y_true, y_pred, squared=False)\n",
    "test_mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "test_mape = metrics.mean_absolute_percentage_error(np.array(y_true) + 1, np.array(y_pred) + 1)\n",
    "\n",
    "# Log metrics to Weights and Biases\n",
    "wandb.log({\n",
    "    'mse': test_mse,\n",
    "    'rmse': test_rmse,\n",
    "    'mae': test_mae,\n",
    "    'mape': test_mape\n",
    "}, commit=True)\n",
    "\n",
    "print(f'MSE: {test_mse:.2f}')\n",
    "print(f'RMSE: {test_rmse:.2f}')\n",
    "print(f'MAE: {test_mae:.2f}')\n",
    "print(f'MAPE: {test_mape:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
