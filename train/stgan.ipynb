{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 3\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOADING DATA: 100%|██████████| 14/14 [00:53<00:00,  3.79s/it]\n",
      "LOADING DATA: 100%|██████████| 14/14 [00:16<00:00,  1.17s/it]\n",
      "LOADING DATA: 100%|██████████| 14/14 [00:16<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from util.dataset import GraphPassengerFlowDataset\n",
    "from util.transform import GraphToTensor, GraphRollExogenousFeatures\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    GraphToTensor(),\n",
    "    GraphRollExogenousFeatures()\n",
    "])\n",
    "\n",
    "train_data = GraphPassengerFlowDataset(\n",
    "    min_date=date(2022, 1, 1),\n",
    "    max_date=date(2023, 1, 1),\n",
    "    transform=transform\n",
    ")\n",
    "validation_data = GraphPassengerFlowDataset(\n",
    "    min_date=date(2023, 1, 1),\n",
    "    max_date=date(2023, 4, 1),\n",
    "    transform=transform)\n",
    "test_data = GraphPassengerFlowDataset(\n",
    "    min_date=date(2023, 4, 1),\n",
    "    max_date=date(2023, 7, 1),\n",
    "    transform=transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "validation_loader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        passengers\ndatetime            origin destination            \n2022-01-01 00:00:00 12     19                159.0\n                           LM                  6.0\n                           OW                 25.0\n                    16     24                 78.0\n                           CC                 82.0\n...                                            ...\n2022-12-31 23:00:00 WD     ED                 17.0\n                    WP     NC                 14.0\n                           PC                 35.0\n                    WS     FM                121.0\n                           ML                 16.0\n\n[893520 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>passengers</th>\n    </tr>\n    <tr>\n      <th>datetime</th>\n      <th>origin</th>\n      <th>destination</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2022-01-01 00:00:00</th>\n      <th rowspan=\"3\" valign=\"top\">12</th>\n      <th>19</th>\n      <td>159.0</td>\n    </tr>\n    <tr>\n      <th>LM</th>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>OW</th>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">16</th>\n      <th>24</th>\n      <td>78.0</td>\n    </tr>\n    <tr>\n      <th>CC</th>\n      <td>82.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2022-12-31 23:00:00</th>\n      <th>WD</th>\n      <th>ED</th>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WP</th>\n      <th>NC</th>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>PC</th>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WS</th>\n      <th>FM</th>\n      <td>121.0</td>\n    </tr>\n    <tr>\n      <th>ML</th>\n      <td>16.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>893520 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_data._data[['passengers']]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        12->19  12->LM  12->OW  16->24  16->CC  19->12  19->MA  24->16   \n12->19     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0  \\\n12->LM     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n12->OW     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n16->24     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n16->CC     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n...        ...     ...     ...     ...     ...     ...     ...     ...   \nWD->ED     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \nWP->NC     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \nWP->PC     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \nWS->FM     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \nWS->ML     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\n        24->GP  AN->PC  ...  UC->FM  UC->SH  WC->LF  WC->PH  WD->CV  WD->ED   \n12->19     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0  \\\n12->LM     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n12->OW     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n16->24     1.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n16->CC     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \nWD->ED     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \nWP->NC     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \nWP->PC     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \nWS->FM     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \nWS->ML     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n\n        WP->NC  WP->PC  WS->FM  WS->ML  \n12->19     0.0     0.0     0.0     0.0  \n12->LM     0.0     0.0     0.0     0.0  \n12->OW     0.0     0.0     0.0     0.0  \n16->24     0.0     0.0     0.0     0.0  \n16->CC     0.0     0.0     0.0     0.0  \n...        ...     ...     ...     ...  \nWD->ED     0.0     0.0     0.0     0.0  \nWP->NC     0.0     0.0     0.0     0.0  \nWP->PC     0.0     0.0     0.0     0.0  \nWS->FM     0.0     0.0     0.0     0.0  \nWS->ML     0.0     0.0     0.0     0.0  \n\n[102 rows x 102 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>12-&gt;19</th>\n      <th>12-&gt;LM</th>\n      <th>12-&gt;OW</th>\n      <th>16-&gt;24</th>\n      <th>16-&gt;CC</th>\n      <th>19-&gt;12</th>\n      <th>19-&gt;MA</th>\n      <th>24-&gt;16</th>\n      <th>24-&gt;GP</th>\n      <th>AN-&gt;PC</th>\n      <th>...</th>\n      <th>UC-&gt;FM</th>\n      <th>UC-&gt;SH</th>\n      <th>WC-&gt;LF</th>\n      <th>WC-&gt;PH</th>\n      <th>WD-&gt;CV</th>\n      <th>WD-&gt;ED</th>\n      <th>WP-&gt;NC</th>\n      <th>WP-&gt;PC</th>\n      <th>WS-&gt;FM</th>\n      <th>WS-&gt;ML</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12-&gt;19</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12-&gt;LM</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12-&gt;OW</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16-&gt;24</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16-&gt;CC</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>WD-&gt;ED</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>WP-&gt;NC</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>WP-&gt;PC</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>WS-&gt;FM</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>WS-&gt;ML</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows × 102 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "station_connections = data.index.droplevel(0).unique()\n",
    "\n",
    "physical_graph = np.zeros((station_connections.size, station_connections.size), dtype=np.float64)\n",
    "for idx, con in enumerate(station_connections):\n",
    "    # Retrieve connections such that `this.dest == that.origin`\n",
    "    neighbours = station_connections[station_connections.get_loc(con[1])]\n",
    "    neighbours = neighbours[neighbours.map(lambda index: index[1] != con[0])]\n",
    "\n",
    "    # Set the edge weight for all neighbours\n",
    "    for n in neighbours:\n",
    "        physical_graph[idx, station_connections.get_loc(n)] = 1.0 / neighbours.size\n",
    "\n",
    "pd.DataFrame(physical_graph, columns=station_connections.to_series().map(lambda con: f'{con[0]}->{con[1]}')).set_index(station_connections.to_series().map(lambda con: f'{con[0]}->{con[1]}'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from models.stgan import STGAN\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = STGAN(\n",
    "        order=(23, 1, 0),\n",
    "        seasonal_lag=24,\n",
    "        seasonal_order=(7, 0, 0),\n",
    "        static_features=7,\n",
    "        exogenous_features=14,\n",
    "        exogenous_window=(-2, 4),\n",
    "        k_steps=4\n",
    ").to(device)\n",
    "\n",
    "criterion = MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1.0e-3, eps=1.0e-4)\n",
    "scheduler = ExponentialLR(optimizer, 0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge features: (102, 102, 1)\n"
     ]
    }
   ],
   "source": [
    "ADJACENCY_MATRIX_NORMALIZATION = False\n",
    "\n",
    "adj_mx = np.stack([physical_graph], axis=-1)\n",
    "if ADJACENCY_MATRIX_NORMALIZATION:\n",
    "    adj_mx = adj_mx / (adj_mx.sum(axis=0) + 1e-18)\n",
    "print('Edge features:', adj_mx.shape)\n",
    "\n",
    "src, dst = adj_mx.sum(axis=-1).nonzero()\n",
    "edge_index = torch.tensor(np.array([src, dst], dtype=np.int_), dtype=torch.long, device=device)\n",
    "edge_attr = torch.tensor(adj_mx[adj_mx.sum(axis=-1) != 0],\n",
    "                         dtype=torch.float,\n",
    "                         device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Log run to Weights and Biases\n",
    "wandb.init(project='passenger-flow-forecasting',\n",
    "           config={'model': 'STGAN'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "EPOCH:   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "298b75e37a884b1f872654b77c52cdff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TRAIN: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28f35e2d6512489cb10f11c7bb0b0f0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0    RMSE: 135.73    MAE:  67.09\n",
      "# 1    RMSE: 126.69    MAE:  56.69\n",
      "# 2    RMSE: 127.43    MAE:  59.62\n",
      "# 3    RMSE: 122.19    MAE:  53.08\n",
      "# 4    RMSE: 120.95    MAE:  52.28\n",
      "# 5    RMSE: 118.94    MAE:  50.90\n",
      "# 6    RMSE: 118.64    MAE:  50.63\n",
      "# 7    RMSE: 117.73    MAE:  50.09\n",
      "# 8    RMSE: 117.45    MAE:  50.20\n",
      "# 9    RMSE: 118.83    MAE:  52.93\n",
      "#10    RMSE: 117.52    MAE:  51.47\n",
      "#11    RMSE: 117.15    MAE:  50.31\n",
      "#12    RMSE: 116.35    MAE:  49.87\n",
      "#13    RMSE: 115.20    MAE:  48.58\n",
      "#14    RMSE: 115.09    MAE:  48.63\n",
      "#15    RMSE: 114.71    MAE:  48.53\n",
      "#16    RMSE: 116.08    MAE:  50.78\n",
      "#17    RMSE: 114.43    MAE:  48.52\n",
      "#18    RMSE: 114.21    MAE:  48.37\n",
      "#19    RMSE: 114.00    MAE:  48.98\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import math\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "EPOCHS = 50  # at least 50, preferably 200\n",
    "last_state = (-1, None)\n",
    "\n",
    "# Create weights directories\n",
    "os.makedirs('weights/stgan/checkpoints', exist_ok=True)\n",
    "\n",
    "tqdm_epoch = tqdm(desc='EPOCH', total=EPOCHS)\n",
    "tqdm_batch = tqdm(desc='TRAIN', total=0)\n",
    "for epoch in range(EPOCHS):\n",
    "    # Set the correct mode for training\n",
    "    model.train()\n",
    "\n",
    "    # Keep track of the training loss\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Loop over training data in batches\n",
    "    tqdm_batch.desc = f'TRAIN #{epoch:03d}'\n",
    "    tqdm_batch.reset(len(train_loader))\n",
    "    for batch in train_loader:\n",
    "        # Move the data to the same device as the model\n",
    "        # Data format: [batch, time, node, feature]\n",
    "        history, horizon = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Select views of data\n",
    "        y = horizon[:, 0, :, 0].squeeze()\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute outputs using a forward pass\n",
    "        outputs = model(history, horizon, edge_index).squeeze()\n",
    "\n",
    "        # Compute the loss of this batch\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Perform a backward pass to update weights\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true += y.cpu().numpy().tolist()\n",
    "        y_pred += outputs.cpu().detach().numpy().tolist()\n",
    "\n",
    "        tqdm_batch.update()\n",
    "\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    train_mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    train_mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # We don't need gradients during validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Loop over validation data in batches\n",
    "        tqdm_batch.desc = f'VALIDATE #{epoch:03d}'\n",
    "        tqdm_batch.reset(len(train_loader))\n",
    "        for batch in train_loader:\n",
    "            # Move the data to the same device as the model\n",
    "            # Data format: [batch, time, node, feature]\n",
    "            history, horizon = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Select views of data\n",
    "            y = horizon[:, 0, :, 0].squeeze()\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute outputs using a forward pass\n",
    "            outputs = model(history, horizon, edge_index).squeeze()\n",
    "\n",
    "            y_true += y.cpu().numpy().tolist()\n",
    "            y_pred += outputs.cpu().detach().numpy().tolist()\n",
    "\n",
    "            tqdm_batch.update()\n",
    "\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    validation_mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    validation_mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    print(f'#{epoch:2d}    RMSE: {math.sqrt(validation_mse):6.2f}    MAE: {validation_mae:6.2f}')\n",
    "\n",
    "    # Decrease learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Log metrics to Weights and Biases\n",
    "    wandb.log({\n",
    "        'train_mse': train_mse,\n",
    "        'train_mae': train_mae,\n",
    "        'validation_mse': validation_mse,\n",
    "        'validation_mae': validation_mae\n",
    "    }, commit=epoch < EPOCHS)\n",
    "\n",
    "    last_state = epoch, model.state_dict()\n",
    "\n",
    "    if epoch < 5 or epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'weights/stgan/checkpoints/{epoch:2d}.pt')\n",
    "\n",
    "    tqdm_epoch.update()\n",
    "\n",
    "tqdm_batch.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Save the trained model\n",
    "now = datetime.now()\n",
    "datestring = f'{now.year}{str(now.month).zfill(2)}{str(now.day).zfill(2)}-{str(now.hour).zfill(2)}{str(now.minute).zfill(2)}'\n",
    "torch.save(last_state[1], f'weights/stgan/{datestring}--{last_state[0]}.pt')\n",
    "torch.save(last_state[1], f'weights/stgan/seed-{SEED}.pt')\n",
    "torch.save(last_state[1], f'weights/stgan/latest.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "if exists(f'weights/stgan/latest.pt'):\n",
    "    model.load_state_dict(torch.load(f'weights/stgan/latest.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Keep track of the loss\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# We don't need to keep track of gradients while testing\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    # Loop over data in batches\n",
    "    for batch in tqdm(test_loader, desc='TEST'):\n",
    "        # Move the data to the same device as the model\n",
    "        # Data format: [batch, time, node, feature]\n",
    "        history, horizon = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Select views of data\n",
    "        y = horizon[:, 0, :, 0].squeeze()\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute outputs using a forward pass\n",
    "        outputs = model(history, horizon, edge_index).squeeze()\n",
    "\n",
    "        y_true += y.cpu().numpy().tolist()\n",
    "        y_pred += outputs.cpu().detach().numpy().tolist()\n",
    "\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "\n",
    "# Cast results to integers\n",
    "y_true = y_true.astype('int')\n",
    "y_pred = y_pred.astype('int')\n",
    "\n",
    "# Drop results where y_true == 0\n",
    "mask = y_true > 0\n",
    "y_true = y_true[mask]\n",
    "y_pred = y_pred[mask]\n",
    "\n",
    "test_mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "test_rmse = metrics.mean_squared_error(y_true, y_pred, squared=False)\n",
    "test_mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "test_mape = metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "# Log metrics to Weights and Biases\n",
    "wandb.log({\n",
    "    'mse': test_mse,\n",
    "    'rmse': test_rmse,\n",
    "    'mae': test_mae,\n",
    "    'mape': test_mape\n",
    "}, commit=True)\n",
    "\n",
    "print(f'MSE: {test_mse:.2f}')\n",
    "print(f'RMSE: {test_rmse:.2f}')\n",
    "print(f'MAE: {test_mae:.2f}')\n",
    "print(f'MAPE: {test_mape:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
